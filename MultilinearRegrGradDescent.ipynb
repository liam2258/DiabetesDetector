{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5OSjJy2VP65B"
      },
      "outputs": [],
      "source": [
        "def costFunction(x, y, theta0, thetas): #Cost function for linear regression\n",
        "   \n",
        "    n = len(x[0])\n",
        "    tCost = 0\n",
        "    \n",
        "    for i in range(n):\n",
        "        yhat = np.dot(x[:,i], thetas) + theta0 #Creating a dot product of every sample (ie row) and the learning weights (thetas) then adding the bias\n",
        "        tCost = tCost + (yhat - y[i])**2\n",
        "    cost = 1 / (2 * n) * tCost\n",
        "\n",
        "    return cost #Returns the mse of the current iteration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5MbyyKB4GoBC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import datasets\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt\n",
        "import random\n",
        "\n",
        "diabetes = datasets.load_diabetes() #Load diabetes dataset\n",
        "\n",
        "X = diabetes.data\n",
        "Y = diabetes.target\n",
        "\n",
        "#Note that the diabetes dataset from sklearn is already feature scaled and normalized\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2) #Size of data used for training is 80%\n",
        "\n",
        "X_train = np.transpose(X_train) #Reorganize data so that every column is a feature i.e. a trait\n",
        "\n",
        "N = len(X_train[0])\n",
        "numFeatures = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "gukGgoiSQE0c",
        "outputId": "9dadcff1-122b-4318-e7bb-005e920072c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final value of learning bias 153.282859318973\n",
            "Final value of learning weights [ -32.18512152 -228.86487091  487.55196487  306.29858106 -444.02966777\n",
            "  179.00186236  -89.35316549   99.48908621  606.65667155  125.092974  ]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training mse: 1522.4094212524965\n",
            "Training rmse: 39.01806531918896\n",
            "Training accuracy: 75.39%\n",
            "\n",
            "Test mse: 2221.266713330374\n",
            "Test rmse: 47.13031628718795\n",
            "test accuracy: 64.09%\n"
          ]
        }
      ],
      "source": [
        "iter = 40000 #Number of steps\n",
        "eta = 0.9 #Learning rate\n",
        "errs = [] #List stores the mse of each iteration\n",
        "\n",
        "theta0 = 0 #Initialize bias as empty\n",
        "\n",
        "#Initialize thetas using 10 outputs from np.random.normal(loc=0.0, scale=1.0), code itself is not included to keep consistency\n",
        "thetas = [0.45435286811439624, 0.7704212959985223, 1.083182783234907, -0.5555893818115545, 0.27691995481038234, 0.4390971075506249, -0.5520405264773913, -0.37439770113092724, 1.3619882998691475, -1.225172826869053]\n",
        "\n",
        "#Gradient descent implementation\n",
        "for j in range(iter):\n",
        "    t0Grad = 0\n",
        "    tGrads = np.zeros(numFeatures)\n",
        "\n",
        "    for i in range(N):\n",
        "        yhat = np.dot(thetas, X_train[:, i]) + theta0\n",
        "\n",
        "        #Update the gradients\n",
        "        t0Grad += (yhat - Y_train[i])\n",
        "        for k in range(numFeatures):\n",
        "            tGrads[k] += (yhat - Y_train[i]) * X_train[k, i]\n",
        "\n",
        "    #Update the parameters\n",
        "    t0Grad /= N\n",
        "    tGrads /= N\n",
        "\n",
        "    errs.append(costFunction(X_train, Y_train, theta0, thetas)) #Calculates the mse of step j and adds it to the errors list\n",
        "    theta0 -= eta * t0Grad\n",
        "    thetas -= eta * tGrads\n",
        "\n",
        "print(\"Final value of learning bias\", theta0)\n",
        "print(\"Final value of learning weights\", thetas)\n",
        "\n",
        "print(\"Plot of mse over each iteration\")\n",
        "plt.plot(errs) #Creates a graph to show mse across each step/iteration\n",
        "plt.show() #Display graph\n",
        "\n",
        "print()\n",
        "print(\"Training mse:\", errs[-1])\n",
        "print(\"Training rmse:\", sqrt(errs[-1]))\n",
        "\n",
        "accuracy = 1 - (errs[-1]/np.var(Y_test)) #Guage accuracy of the model on the test set\n",
        "print(\"Training accuracy: {:.2f}%\".format(accuracy*100)) #Display accuracy\n",
        "\n",
        "Y_pred = np.dot(X_test, thetas) + theta0 #Use model to make predictions on test data\n",
        "mse = mean_squared_error(Y_test, Y_pred) #Create mse based on the actual test results and model predictions\n",
        "\n",
        "print()\n",
        "print(\"Test mse:\", mse)\n",
        "print(\"Test rmse:\", sqrt(mse))\n",
        "\n",
        "accuracy = 1 - (mse/np.var(Y_test)) #Guage accuracy of the model on the test set\n",
        "print(\"Test accuracy: {:.2f}%\".format(accuracy*100)) #Display accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experimenting with learning rate and iterations:\n",
        "\n",
        "Steps 10000\n",
        "Step Size 0.05\n",
        "Training mse: 1590.9837605527873\n",
        "Training rmse: 39.88713778341067\n",
        "Training accuracy: 74.28%\n",
        "Test mse: 2411.7544361185046\n",
        "Test rmse: 49.10961653402014\n",
        "test accuracy: 61.01%\n",
        "\n",
        "Steps 15000\n",
        "Step Size 0.05\n",
        "Training mse: 1550.9711738047768\n",
        "Training rmse: 39.38237135832195\n",
        "Training accuracy: 74.92%\n",
        "Test mse: 2321.117352483069\n",
        "Test rmse: 48.17797580308942\n",
        "test accuracy: 62.47%\n",
        "\n",
        "Steps 20000\n",
        "Step Size 0.05\n",
        "Training mse: 1538.079694717595\n",
        "Training rmse: 39.21835915381462\n",
        "Training accuracy: 75.13%\n",
        "Test mse: 2284.7829636071106\n",
        "Test rmse: 47.79940338128825\n",
        "test accuracy: 63.06%\n",
        "\n",
        "Steps 30000\n",
        "Step Size 0.05\n",
        "Training mse: 1531.9100836425177\n",
        "Training rmse: 39.13962293689756\n",
        "Training accuracy: 75.23%\n",
        "Test mse: 2255.199284776595\n",
        "Test rmse: 47.48893855179956\n",
        "test accuracy: 63.54%\n",
        "\n",
        "Steps 40000\n",
        "Step Size 0.05\n",
        "Training mse: 1530.800581567458\n",
        "Training rmse: 39.12544672674624\n",
        "Training accuracy: 75.25%\n",
        "Test mse: 2243.595388394273\n",
        "Test rmse: 47.366606257935274\n",
        "test accuracy: 63.73%\n",
        "\n",
        "Steps 40000\n",
        "Step Size 0.051\n",
        "Training mse: 1530.756556260715\n",
        "Training rmse: 39.12488410539659\n",
        "Training accuracy: 75.25%\n",
        "Test mse: 2243.0070684386424\n",
        "Test rmse: 47.36039556885734\n",
        "test accuracy: 63.73%\n",
        "\n",
        "Steps 40000\n",
        "Step Size 0.055\n",
        "Training mse: 1530.6064611689503\n",
        "Training rmse: 39.12296590455471\n",
        "Training accuracy: 75.25%\n",
        "Test mse: 2240.9757874481015\n",
        "Test rmse: 47.338945778799314\n",
        "test accuracy: 63.77%\n",
        "\n",
        "Steps 40000\n",
        "Step Size 0.07\n",
        "Training mse: 1530.2218327370942\n",
        "Training rmse: 39.118049960818524\n",
        "Training accuracy: 75.26%\n",
        "Test mse: 2236.4010341907097\n",
        "Test rmse: 47.29060196477425\n",
        "test accuracy: 63.84%\n",
        "\n",
        "Steps 40000\n",
        "Step Size 0.1\n",
        "Training mse: 1529.6680073856446\n",
        "Training rmse: 39.11097042244854\n",
        "Training accuracy: 75.27%\n",
        "Test mse: 2233.142264044247\n",
        "Test rmse: 47.25613467100591\n",
        "test accuracy: 63.89%\n",
        "\n",
        "Steps 40000\n",
        "Step Size 0.3\n",
        "Training mse: 1526.9873750213344\n",
        "Training rmse: 39.076685824431614\n",
        "Training accuracy: 75.31%\n",
        "Test mse: 2228.1978309839287\n",
        "Test rmse: 47.20379043026025\n",
        "test accuracy: 63.97%\n",
        "\n",
        "Steps 40000\n",
        "Step Size 0.6\n",
        "Training mse: 1524.2495624368823\n",
        "Training rmse: 39.041638828779746\n",
        "Training accuracy: 75.36%\n",
        "Test mse: 2223.661444376793\n",
        "Test rmse: 47.15571486444451\n",
        "test accuracy: 64.05%\n",
        "\n",
        "Steps 40000\n",
        "Step Size 0.9\n",
        "Training mse: 1522.4094212524965\n",
        "Training rmse: 39.01806531918896\n",
        "Training accuracy: 75.39%\n",
        "Test mse: 2221.266713330374\n",
        "Test rmse: 47.13031628718795\n",
        "test accuracy: 64.09%"
      ],
      "metadata": {
        "id": "leAXxNk7BRDS"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}